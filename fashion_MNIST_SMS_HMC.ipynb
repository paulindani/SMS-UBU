{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bGU6NwlsXFSt"
   },
   "outputs": [],
   "source": [
    "#@title Import Dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from typing import TypeVar, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "from counterfactuals.utils import make_dir, get_transforms, torch_to_image, expl_to_image\n",
    "from counterfactuals.plot import plot_grid_part\n",
    "from counterfactuals.generative_models.base import GenerativeModel\n",
    "from counterfactuals.classifiers.base import NeuralNet\n",
    "\n",
    "Tensor = TypeVar('torch.tensor')\n",
    "\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "import click\n",
    "from argparse import Namespace\n",
    "import ast\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from counterfactuals.classifiers.base import NeuralNet\n",
    "import torch.nn.functional as F\n",
    "from typing import TypeVar, Tuple\n",
    "import counterfactuals.classifiers.cnn as classifiers\n",
    "import counterfactuals.classifiers.unet as unet\n",
    "from counterfactuals.utils import load_checkpoint\n",
    "from counterfactuals.data import get_data_info\n",
    "from counterfactuals.generative_models.factory import get_generative_model\n",
    "import gdown\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bNfVLRUYqZA"
   },
   "outputs": [],
   "source": [
    "#@title Define Hyperparameters\n",
    "\n",
    "# class_names = [\"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\",\n",
    "#                 \"Big_Lips\", \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\",\n",
    "#                 \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\",\n",
    "#                 \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \"Oval_Face\", \"Pale_Skin\",\n",
    "#                 \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\",\n",
    "#                 \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\",\n",
    "#                 \"Wearing_Necktie\", \"Young\"]\n",
    "# num_classes = 40\n",
    "# data_shape = [3, 64, 64]\n",
    "# n_bits = 5\n",
    "# temp = 0.7\n",
    "# data_mean = [0.485, 0.456, 0.406]\n",
    "# data_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "input_size = 28*28*1 # img_size = (28,28) ---> 28*28=784 in total\n",
    "batch_size = 1000 # the size of input data took for one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lCsBCXMwbpH5"
   },
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2\n",
    "# transform_RandomErasing=transforms.Compose([v2.RandomErasing(),\n",
    "#                               transforms.ToTensor()])\n",
    "#from torchvision.transforms import v2\n",
    "#transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=0,std=1.0)])\n",
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "train_data = dsets.FashionMNIST(root = './data', train=True, transform = transform, download = True)\n",
    "test_data = dsets.FashionMNIST(root = './data', train=False, transform = transform, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rfDPBdnYgfGp"
   },
   "outputs": [],
   "source": [
    "#@title Loading the data\n",
    "\n",
    "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvmx=torch.zeros([3*64*64,3*64*64],device=device)\n",
    "images_list=[]\n",
    "labels_list=[]\n",
    "no_batches=len(train_gen)\n",
    "#images_mean=torch.zeros(3,64,64,device=device)\n",
    "for i ,(images,labels) in enumerate(train_gen):\n",
    "    images = Variable(images).cuda().detach()\n",
    "    labels=Variable(labels).cuda().detach()\n",
    "    # images_mean=images_mean+images.mean(0)\n",
    "    # im=torch.reshape(images,[images.shape[0],3*64*64])\n",
    "    # cvmx+=torch.matmul(torch.transpose(im,0,1),im)\n",
    "    if(i<(len(train_gen))):\n",
    "        images_list.append(images)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "\n",
    "\n",
    "test_images_list=[]\n",
    "test_labels_list=[]\n",
    "test_no_batches=len(test_gen)\n",
    "for i ,(images,labels) in enumerate(test_gen):\n",
    "    images = Variable(images).cuda().detach()\n",
    "    labels=Variable(labels).cuda().detach()\n",
    "    if(i<(len(test_gen))):\n",
    "        test_images_list.append(images)\n",
    "        test_labels_list.append(labels)\n",
    "\n",
    "train_data_len=len(train_data)\n",
    "test_data_len=len(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fL-YXTvghaz_"
   },
   "outputs": [],
   "source": [
    "#@title Define model class\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from counterfactuals.classifiers.base import NeuralNet\n",
    "import torch.nn.functional as F\n",
    "from counterfactuals.utils import load_checkpoint\n",
    "from counterfactuals.utils import save_checkpoint\n",
    "\n",
    "from typing import TypeVar, Tuple\n",
    "\n",
    "Tensor = TypeVar('torch.tensor')\n",
    "\n",
    "\n",
    "class multinomial(NeuralNet):\n",
    "    \"\"\"\n",
    "    CNN for (binary) classification for CelebA, CheXpert\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_classes: int = 10,\n",
    "                 flattened_size: int = 28*28):\n",
    "        \"\"\"Builder.\"\"\"\n",
    "        super(multinomial, self).__init__()\n",
    "\n",
    "        self.last_layer=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "\n",
    "        x=self.last_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def classify(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        net_out = self.forward(x)\n",
    "        acc = F.softmax(net_out, dim=1)\n",
    "        class_idx = torch.max(net_out, 1)[1]\n",
    "\n",
    "        return acc, acc[0, class_idx], class_idx\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=Fashion_MNIST_CNN()\n",
    "# n=0\n",
    "# for par in net.parameters():\n",
    "#     n+=par.numel()\n",
    "\n",
    "# n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ePLIwvAFj2zH"
   },
   "outputs": [],
   "source": [
    "#@title Define loss-function & optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def images_regulariser(net): \n",
    "    li_reg_loss = 0\n",
    "    penalized     = [p for name,p in net.named_parameters() if 'bias' not in name]\n",
    "    not_penalized = [p for name,p in net.named_parameters() if 'bias' in name]\n",
    "    for p in penalized:\n",
    "        li_reg_loss += (p**2).sum()*0.5\n",
    "    #for p in net.parameters():\n",
    "#        li_reg_loss += (p**2).sum()*0.5\n",
    "    reg=li_reg_loss/(train_data_len)*l2regconst\n",
    "    return(reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnet(net,net2):\n",
    "    for param1, param2 in zip(net.parameters(), net2.parameters()):\n",
    "     param1.data += param2.data\n",
    "\n",
    "def multiplynet(net,a):\n",
    "   for param1 in net.parameters():\n",
    "     param1.data *=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def U(x,v,hc,xi1,xi2):\n",
    "\n",
    "    xn=x+hc.etam1g*v+hc.c11*xi1\n",
    "    vn=v*hc.eta+hc.c21*xi1+hc.c22*xi2\n",
    "    return([xn, vn])\n",
    "\n",
    "def bounce(x,v,xstar,width):\n",
    "    vsign=(((x-xstar+width)/(2*width)).floor()% 2)*(-2)+1\n",
    "    vn=v*vsign\n",
    "    xn=((x-xstar-width)% (4*width)-2*width).abs()-width+xstar  \n",
    "    return([xn, vn])\n",
    "\n",
    "def bouncenet():\n",
    "    for p,p_star in zip(net.parameters(),net_star.parameters()):\n",
    "        [p.data, p.v]=bounce(p.data, p.v, p_star.data, 6/torch.sqrt(l2regconst_extra))\n",
    "\n",
    "def svrg_grad(net, batch_it):\n",
    "    outputsU = net(images_list[batch_it])\n",
    "    loss_likelihood = loss_function(outputsU, labels_list[batch_it])  \n",
    "\n",
    "\n",
    "    grads_reg=[torch.zeros_like(par) for par in net.parameters()]\n",
    "    net_pars=list(net.parameters())\n",
    "    with torch.no_grad():\n",
    "        for it in range(len_params):\n",
    "            if(list_no_bias[it]):\n",
    "                grads_reg[it]=net_pars[it].data*l2regconst\n",
    "\n",
    "    net.zero_grad()\n",
    "    loss_likelihood.backward()\n",
    "    with torch.no_grad():\n",
    "        grads_likelihood=[par.grad*batch_size for par in net.parameters()]\n",
    "\n",
    "        svrg_grads=[]\n",
    "        for p,grad,grad_reg,p_star,grad_star,star_sum_grad in zip(list(net.parameters()),grads_likelihood,grads_reg,list(net_star.parameters()),net_star_grad_list[batch_it],net_star_full_grad):              \n",
    "            svrg_grads.append(grad_reg+star_sum_grad+(grad-grad_star)*no_batches+l2regconst_extra*(p.data-p_star.data))\n",
    "    return svrg_grads,loss_likelihood.data\n",
    "\n",
    "def full_grad(net):\n",
    "    outputs = net(all_images)\n",
    "    net.zero_grad()\n",
    "    full_loss = (loss_function(outputs, all_labels)+images_regulariser(net))*train_data_len\n",
    "    full_loss.backward()\n",
    "    grads=[par.grad for par in net.parameters()]\n",
    "\n",
    "    return grads,full_loss.data\n",
    "\n",
    "\n",
    "def leapfrogvxv_step(net,h,batch_it):   \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p in net.parameters():\n",
    "            p+=(h/2)*p.v\n",
    "\n",
    "    svrg_grads,_=svrg_grad(net, batch_it)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), svrg_grads):\n",
    "            p.v-=h*grad\n",
    "            p+=(h/2)*p.v\n",
    "\n",
    "def leaponlyv(net,h,batch_it):   \n",
    "    svrg_grads,_=svrg_grad(net, batch_it)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), svrg_grads):\n",
    "            p.v-=h*grad\n",
    "\n",
    "\n",
    "def leapforward(net,h,batch_it):   \n",
    "    svrg_grads,_=svrg_grad(net, batch_it)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), svrg_grads):\n",
    "            p.v-=h*grad\n",
    "    with torch.no_grad():\n",
    "        for p in net.parameters():\n",
    "            p.data+=(h*no_batches/(no_batches-1))*p.v\n",
    "\n",
    "def leapbackward(net,h,batch_it):   \n",
    "           #p.data+=(h/2)*p.v\n",
    "    with torch.no_grad():\n",
    "        for p in net.parameters():\n",
    "            p.data+=(h*no_batches*2/(no_batches*2-1))*p.v\n",
    "    svrg_grads,_=svrg_grad(net, batch_it)\n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), svrg_grads):\n",
    "            p.v-=h*grad\n",
    "\n",
    "def leapfrog_step(net,h):   \n",
    "    grads,_=full_grad(net)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), grads):\n",
    "            p.v-=(h/2)*grad\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p in net.parameters():\n",
    "            p.data+=(h)*p.v\n",
    "\n",
    "    grads,_=full_grad(net)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p,grad in zip(net.parameters(), grads):\n",
    "            p.v-=(h/2)*grad\n",
    "\n",
    "\n",
    "def hamiltonian(net):\n",
    "    with torch.no_grad():\n",
    "        outputs = net(all_images)\n",
    "        ham=loss_function(outputs, all_labels)*train_data_len+images_regulariser(net)*train_data_len\n",
    "        for par in net.parameters():\n",
    "            ham+=par.v.pow(2).sum()/2\n",
    "        return(ham)\n",
    "\n",
    "\n",
    "\n",
    "def ind_create(batch_it):\n",
    "    modit=batch_it %(2*no_batches)\n",
    "    ind=(modit<=(no_batches-1))*modit+(modit>=no_batches)*(2*no_batches-modit-1)\n",
    "    return ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Fashion_MNIST_CNN().cuda()\n",
    "#net2=copy.deepcopy(net)\n",
    "#addnet(net2,net)\n",
    "#multiplynet(net2,1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath=\"output_fashion_low_rank_9n.pickle\"\n",
    "# #filepath=\"output_fashion_low_rank_long.pickle\"\n",
    "# with open(filepath,\"rb\") as file:\n",
    "#    [labels_arr,test_labels_arr,test_prob_arr]=pickle.load(file)\n",
    "# labels_arr=torch.tensor(labels_arr).detach()\n",
    "# test_labels_arr=torch.tensor(test_labels_arr).detach()\n",
    "# test_prob_arr=torch.tensor(test_prob_arr).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome should be a binary list of the ordinal outcome. [0, 1, 0] for exmaple.\n",
    "# Probs should be a list of probabilities. [0.79, 0.09, 0.12] for example.\n",
    "# Outcome and Probs must be provided with the same order as probabilities.\n",
    "\n",
    "def rps_single(probs, true_label):\n",
    "    outcome=torch.zeros(num_classes)\n",
    "    outcome[true_label.int()]=1.0\n",
    "    cum_probs = torch.cumsum(probs,0)\n",
    "    cum_outcomes = torch.cumsum(outcome,0)\n",
    "    \n",
    "    #print(cum_outcomes)\n",
    "    #print(cum_probs)\n",
    "    sum_rps = 0\n",
    "    for i in range(len(outcome)):         \n",
    "        sum_rps+= (cum_probs[i] - cum_outcomes[i])**2\n",
    "    \n",
    "    return sum_rps/(num_classes-1)\n",
    "\n",
    "def rps_calc(test_probs, true_labels):\n",
    "    rps_vec=torch.zeros(test_data_len)\n",
    "    for it in range(test_data_len):\n",
    "        rps_vec[it]=rps_single(test_probs[it,:].reshape(num_classes),true_labels[it])\n",
    "    return rps_vec\n",
    "\n",
    "def nll_calc(test_probs, true_labels):\n",
    "    res=0\n",
    "    for it in range(test_data_len):\n",
    "        res-=torch.log(test_probs[it,true_labels[it].int()])\n",
    "    return res/test_data_len\n",
    "\n",
    "def adaptive_calibration_error(test_probs,true_labels, num_bins=20):\n",
    "    max_probs, predicted_labels = torch.max(test_probs,1)\n",
    "    ind=torch.argsort(max_probs,stable=True)\n",
    "    sorted_max_probs=max_probs[ind]\n",
    "    sorted_predicted_labels=predicted_labels[ind]\n",
    "    sorted_true_labels=true_labels[ind]\n",
    "\n",
    "    correct = (sorted_predicted_labels == sorted_true_labels).clone().detach().float()\n",
    "    bins=(torch.tensor(range(test_data_len))/torch.tensor(test_data_len/num_bins)).floor()\n",
    "\n",
    "    o=torch.tensor(0.0)\n",
    "    for b in range(num_bins):\n",
    "        mask = (bins == b)\n",
    "        if torch.any(mask):\n",
    "            #print(b, sorted_max_probs[mask].mean(), (correct[mask] - sorted_max_probs[mask]).mean())\n",
    "            o += (correct[mask] - sorted_max_probs[mask]).mean().abs()\n",
    "\n",
    "    return o / num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u75Xa5VckuTH"
   },
   "outputs": [],
   "source": [
    "#@title Output arrays\n",
    "num_classes=10\n",
    "\n",
    "training_size=no_batches*batch_size\n",
    "test_size=test_data_len\n",
    "\n",
    "\n",
    "#l2regconst=torch.tensor(50).detach()\n",
    "l2regconst=torch.tensor(10).detach()\n",
    "l2regconst_extra=torch.tensor(0).detach()\n",
    "gam=torch.sqrt(l2regconst)\n",
    "#hper2c=hper2const(torch.tensor(h/2),gam)\n",
    "all_images=torch.cat(images_list,dim=0).detach()\n",
    "all_labels=torch.cat(labels_list,dim=0).detach()\n",
    "# net = multinomial().cuda()\n",
    "# net2 = multinomial().cuda()\n",
    "# net.train()\n",
    "# net2.train()\n",
    "\n",
    "def find_MAP(num_steps):\n",
    "  net = multinomial().cuda()\n",
    "\n",
    "  def lpost():\n",
    "    outputs = net(all_images)    \n",
    "    loss_likelihood = loss_function(outputs, all_labels)\n",
    "    reg=images_regulariser(net)\n",
    "    loss=loss_likelihood+reg\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    return(loss)\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(net.parameters(), history_size=30, max_iter=20)\n",
    "  for epoch in range(num_steps):\n",
    "    optimizer.step(lpost)\n",
    "  \n",
    "  net_star=copy.deepcopy(net)\n",
    "  len_params=len(list(net_star.parameters()))\n",
    "  #Variance reduction - saving gradients at each batch at x_star\n",
    "  net_star_grad_list=[]\n",
    "  net_star_full_grad=[torch.zeros_like(par, device=device) for par in list(net_star.parameters())]\n",
    "  for i in range(no_batches):\n",
    "      images=images_list[i]\n",
    "      labels=labels_list[i]\n",
    "      outputs=net_star(images)\n",
    "      loss_likelihood = loss_function(outputs, labels)\n",
    "      #reg=images_regulariser(net)\n",
    "      net_star.zero_grad()\n",
    "      loss_likelihood.backward()\n",
    "      grads=[par.grad*batch_size for par in list(net_star.parameters())]\n",
    "      net_star_grad_list.append(grads)\n",
    "      for g, gi in zip(net_star_full_grad,grads):\n",
    "        g+=gi          \n",
    "\n",
    "  len_params=len(list(net_star.parameters()))\n",
    "  list_no_bias=torch.zeros(len_params)\n",
    "  pit=0\n",
    "  for name, p in net_star.named_parameters():\n",
    "      if 'bias' not in name:\n",
    "          list_no_bias[pit]=1.0\n",
    "      pit+=1\n",
    "  return net_star, net_star_grad_list, net_star_full_grad, len_params, list_no_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_star, net_star_grad_list, net_star_full_grad, len_params, list_no_bias=find_MAP(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=torch.cat(images_list,dim=0).detach()\n",
    "all_labels=torch.cat(labels_list,dim=0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMS_HMC(num_steps,num_symmetric_sweeps,h,partial):\n",
    "  net=copy.deepcopy(net_star)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_labels_arr=torch.zeros(test_size).detach()\n",
    "    test_prob_arr=torch.zeros([test_size,num_classes,num_steps]).detach()\n",
    "  #Initialise velocities\n",
    "    rejects=0  \n",
    "    for par in net.parameters():\n",
    "      par.v = torch.randn_like(par.data,device=device).detach()\n",
    "    net_old=copy.deepcopy(net)\n",
    "    for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "      par_old.v = par.v\n",
    "\n",
    "    #ham_old=hamiltonian(net).detach()\n",
    "\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    print(\"Step:\", step, \"Rejects:\", rejects)\n",
    "    rperm=random.permutation(list(range(no_batches))) \n",
    "    #h_factor=torch.rand(1).detach().cuda()      \n",
    "    ham_old=hamiltonian(net).detach()    \n",
    "    for s in range(num_symmetric_sweeps):\n",
    "      for i in range(no_batches*2):\n",
    "        ind=ind_create(i)\n",
    "        leapfrogvxv_step(net,h,rperm[ind])\n",
    "    r=torch.rand(1).detach().cuda()\n",
    "    ham_new=hamiltonian(net)\n",
    "    print(\"Hamiltonian diff:\", ham_old-ham_new)    \n",
    "    if(r.log()>(ham_old-ham_new)):\n",
    "      net=copy.deepcopy(net_old)\n",
    "      for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "        par.v = par_old.v\n",
    "      rejects+=1\n",
    "      for par in net.parameters():\n",
    "        par.v = -par.v\n",
    "\n",
    "    for par in net.parameters():\n",
    "      par.v = par.v*partial+torch.randn_like(par.data,device=device).detach()*((1-partial**2)**(1/2))\n",
    "\n",
    "    net_old=copy.deepcopy(net)\n",
    "    for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "      par_old.v = par.v \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "      for testit in range(test_no_batches):\n",
    "        imagest=test_images_list[testit]\n",
    "        labelst=test_labels_list[testit]\n",
    "        actual_batch_size=len(imagest)\n",
    "        test_labels_arr[(testit*batch_size):(testit*batch_size+actual_batch_size)]=labelst.detach().cpu()\n",
    "        outputt = net(imagest).detach()#.reshape(actual_batch_size).detach()\n",
    "        _, predictedt = torch.max(outputt,1)\n",
    "        #_, predictedt2 = torch.max(outputt2,1)\n",
    "        correct += (predictedt == labelst).sum()\n",
    "        total += labelst.size(0)\n",
    "\n",
    "        test_prob_arr[(testit*batch_size):(testit*batch_size+actual_batch_size),0:num_classes,step]=torch.softmax(outputt,dim=1)    \n",
    "    #net.train()       \n",
    "    print('Test accuracy of the model: %.3f %%' %((100*correct)/(total+1)))\n",
    "    print('Step [%d], Average Loss: %0.4f' %(step+1, ham_old/train_data_len))\n",
    "  return(test_labels_arr,test_prob_arr,rejects)\n",
    "\n",
    "\n",
    "def SMS_HMC2(num_steps,num_symmetric_sweeps,h,partial):\n",
    "  net=copy.deepcopy(net_star)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_labels_arr=torch.zeros(test_size).detach()\n",
    "    test_prob_arr=torch.zeros([test_size,num_classes,num_steps]).detach()\n",
    "  #Initialise velocities\n",
    "    rejects=0  \n",
    "    for par in net.parameters():\n",
    "      par.v = torch.randn_like(par.data,device=device).detach()\n",
    "    net_old=copy.deepcopy(net)\n",
    "    for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "      par_old.v = par.v\n",
    "\n",
    "    #ham_old=hamiltonian(net).detach()\n",
    "\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    print(\"Step:\", step, \"Rejects:\", rejects)\n",
    "    rperm=random.permutation(list(range(no_batches))) \n",
    "    #h_factor=torch.rand(1).detach().cuda()      \n",
    "    ham_old=hamiltonian(net).detach()    \n",
    "    for s in range(num_symmetric_sweeps):\n",
    "      for i in range(no_batches*2):\n",
    "        ind=ind_create(i)\n",
    "        if(i<(no_batches-1)):\n",
    "          leapforward(net,h,rperm[ind])\n",
    "        if(i>(no_batches)):\n",
    "          leapbackward(net,h,rperm[ind])\n",
    "        if(i==(no_batches-1) or i==(no_batches)):\n",
    "          leaponlyv(net,h,rperm[ind])\n",
    "    r=torch.rand(1).detach().cuda()\n",
    "    ham_new=hamiltonian(net)\n",
    "    print(\"Hamiltonian diff:\", ham_old-ham_new)    \n",
    "    if(r.log()>(ham_old-ham_new)):\n",
    "      net=copy.deepcopy(net_old)\n",
    "      for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "        par.v = par_old.v\n",
    "      rejects+=1\n",
    "      for par in net.parameters():\n",
    "        par.v = -par.v\n",
    "    # else:\n",
    "    #   ham_old=ham_new\n",
    "    for par in net.parameters():\n",
    "      par.v = par.v*partial+torch.randn_like(par.data,device=device).detach()*((1-partial**2)**(1/2))\n",
    "\n",
    "    net_old=copy.deepcopy(net)\n",
    "    for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "      par_old.v = par.v \n",
    "    # ham_diff=0\n",
    "    # for par in net.parameters():\n",
    "    #   ham_diff-=par.v.pow(2).sum()/2\n",
    "    #   par.v = torch.randn_like(par.data,device=device).detach()\n",
    "    #   ham_diff+=par.v.pow(2).sum()/2\n",
    "    # ham_old+=ham_diff\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "      for testit in range(test_no_batches):\n",
    "        imagest=test_images_list[testit]\n",
    "        labelst=test_labels_list[testit]\n",
    "        actual_batch_size=len(imagest)\n",
    "        test_labels_arr[(testit*batch_size):(testit*batch_size+actual_batch_size)]=labelst.detach().cpu()\n",
    "        outputt = net(imagest).detach()#.reshape(actual_batch_size).detach()\n",
    "        _, predictedt = torch.max(outputt,1)\n",
    "        #_, predictedt2 = torch.max(outputt2,1)\n",
    "        correct += (predictedt == labelst).sum()\n",
    "        total += labelst.size(0)\n",
    "\n",
    "        test_prob_arr[(testit*batch_size):(testit*batch_size+actual_batch_size),0:num_classes,step]=torch.softmax(outputt,dim=1)    \n",
    "    #net.train()       \n",
    "    print('Test accuracy of the model: %.3f %%' %((100*correct)/(total+1)))\n",
    "    print('Step [%d], Average Loss: %0.4f' %(step+1, ham_old/train_data_len))\n",
    "  return(test_labels_arr,test_prob_arr,rejects)\n",
    "\n",
    "\n",
    "def HMC(num_steps,num_leapfrog,h,partial):\n",
    "  net=copy.deepcopy(net_star)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_labels_arr=torch.zeros(test_size).detach()\n",
    "    test_prob_arr=torch.zeros([test_size,num_classes,num_steps]).detach()\n",
    "  #Initialise velocities\n",
    "    rejects=0  \n",
    "    for par in net.parameters():\n",
    "      par.v = torch.randn_like(par.data,device=device).detach()\n",
    "\n",
    "    #ham_old=hamiltonian(net).detach()\n",
    "\n",
    "    \n",
    "  for step in range(num_steps):\n",
    "    print(\"Step:\", step, \"Rejects:\", rejects)\n",
    "    #h_factor=torch.rand(1).detach().cuda()      \n",
    "\n",
    "    net_old=copy.deepcopy(net)\n",
    "    for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "      par_old.v = par.v\n",
    "    \n",
    "    ham_old=hamiltonian(net_old).detach()    \n",
    "    for s in range(num_leapfrog):\n",
    "      leapfrog_step(net,h)\n",
    "    r=torch.rand(1).detach().cuda()\n",
    "    ham_new=hamiltonian(net).detach()\n",
    "    print(\"Hamiltonian diff:\", ham_old-ham_new)    \n",
    "    if(r.log()>(ham_old-ham_new)):\n",
    "      net=copy.deepcopy(net_old)\n",
    "      for par_old,par in zip(net_old.parameters(),net.parameters()):\n",
    "        par.v = par_old.v\n",
    "      rejects+=1\n",
    "      for par in net.parameters():\n",
    "        par.v = -par.v\n",
    "\n",
    "\n",
    "    for par in net.parameters():\n",
    "      par.v = par.v*partial+torch.randn_like(par.data,device=device).detach()*((1-partial**2)**(1/2))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "      for testit in range(test_no_batches):\n",
    "        imagest=test_images_list[testit]\n",
    "        labelst=test_labels_list[testit]\n",
    "        actual_batch_size=len(imagest)\n",
    "        test_labels_arr[(testit*batch_size):(testit*batch_size+actual_batch_size)]=labelst.detach().cpu()\n",
    "        outputt = net(imagest).detach()#.reshape(actual_batch_size).detach()\n",
    "        _, predictedt = torch.max(outputt,1)\n",
    "        correct += (predictedt == labelst).sum()\n",
    "        total += labelst.size(0)\n",
    "\n",
    "        test_prob_arr[(testit*batch_size):(testit*batch_size+actual_batch_size),0:num_classes,step]=torch.softmax(outputt,dim=1)    \n",
    "    #net.train()       \n",
    "    print('Test accuracy of the model: %.3f %%' %((100*correct)/(total+1)))\n",
    "    print('Step [%d], Average Loss: %0.4f' %(step+1, ham_old/train_data_len))\n",
    "  return(test_labels_arr,test_prob_arr,rejects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Rejects: 0\n",
      "Hamiltonian diff: tensor(-0.9199, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [1], Average Loss: 0.4549\n",
      "Step: 1 Rejects: 0\n",
      "Hamiltonian diff: tensor(-0.0254, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [2], Average Loss: 0.4722\n",
      "Step: 2 Rejects: 1\n",
      "Hamiltonian diff: tensor(-1.0879, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [3], Average Loss: 0.4687\n",
      "Step: 3 Rejects: 2\n",
      "Hamiltonian diff: tensor(-0.4160, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [4], Average Loss: 0.4771\n",
      "Step: 4 Rejects: 3\n",
      "Hamiltonian diff: tensor(-0.4609, device='cuda:0')\n",
      "Test accuracy of the model: 84.052 %\n",
      "Step [5], Average Loss: 0.4751\n",
      "Step: 5 Rejects: 3\n",
      "Hamiltonian diff: tensor(-1.1191, device='cuda:0')\n",
      "Test accuracy of the model: 84.052 %\n",
      "Step [6], Average Loss: 0.4897\n",
      "Step: 6 Rejects: 4\n",
      "Hamiltonian diff: tensor(0.0059, device='cuda:0')\n",
      "Test accuracy of the model: 83.802 %\n",
      "Step [7], Average Loss: 0.4938\n",
      "Step: 7 Rejects: 4\n",
      "Hamiltonian diff: tensor(-0.4980, device='cuda:0')\n",
      "Test accuracy of the model: 83.992 %\n",
      "Step [8], Average Loss: 0.5069\n",
      "Step: 8 Rejects: 4\n",
      "Hamiltonian diff: tensor(0.7207, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [9], Average Loss: 0.5084\n",
      "Step: 9 Rejects: 4\n",
      "Hamiltonian diff: tensor(-0.8984, device='cuda:0')\n",
      "Test accuracy of the model: 83.882 %\n",
      "Step [10], Average Loss: 0.5121\n",
      "Step: 10 Rejects: 4\n",
      "Hamiltonian diff: tensor(-1.3145, device='cuda:0')\n",
      "Test accuracy of the model: 83.882 %\n",
      "Step [11], Average Loss: 0.5146\n",
      "Step: 11 Rejects: 5\n",
      "Hamiltonian diff: tensor(0.3145, device='cuda:0')\n",
      "Test accuracy of the model: 83.602 %\n",
      "Step [12], Average Loss: 0.5145\n",
      "Step: 12 Rejects: 5\n",
      "Hamiltonian diff: tensor(0.0762, device='cuda:0')\n",
      "Test accuracy of the model: 84.102 %\n",
      "Step [13], Average Loss: 0.5267\n",
      "Step: 13 Rejects: 5\n",
      "Hamiltonian diff: tensor(0.2832, device='cuda:0')\n",
      "Test accuracy of the model: 84.282 %\n",
      "Step [14], Average Loss: 0.5278\n",
      "Step: 14 Rejects: 5\n",
      "Hamiltonian diff: tensor(0.1191, device='cuda:0')\n",
      "Test accuracy of the model: 83.742 %\n",
      "Step [15], Average Loss: 0.5238\n",
      "Step: 15 Rejects: 5\n",
      "Hamiltonian diff: tensor(0.6562, device='cuda:0')\n",
      "Test accuracy of the model: 83.622 %\n",
      "Step [16], Average Loss: 0.5232\n",
      "Step: 16 Rejects: 5\n",
      "Hamiltonian diff: tensor(-0.2402, device='cuda:0')\n",
      "Test accuracy of the model: 83.962 %\n",
      "Step [17], Average Loss: 0.5225\n",
      "Step: 17 Rejects: 5\n",
      "Hamiltonian diff: tensor(-0.2305, device='cuda:0')\n",
      "Test accuracy of the model: 83.902 %\n",
      "Step [18], Average Loss: 0.5231\n",
      "Step: 18 Rejects: 5\n",
      "Hamiltonian diff: tensor(-0.0645, device='cuda:0')\n",
      "Test accuracy of the model: 83.742 %\n",
      "Step [19], Average Loss: 0.5245\n",
      "Step: 19 Rejects: 5\n",
      "Hamiltonian diff: tensor(-0.5879, device='cuda:0')\n",
      "Test accuracy of the model: 83.742 %\n",
      "Step [20], Average Loss: 0.5223\n",
      "Step: 20 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.1348, device='cuda:0')\n",
      "Test accuracy of the model: 83.682 %\n",
      "Step [21], Average Loss: 0.5229\n",
      "Step: 21 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.2227, device='cuda:0')\n",
      "Test accuracy of the model: 83.422 %\n",
      "Step [22], Average Loss: 0.5344\n",
      "Step: 22 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.2910, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [23], Average Loss: 0.5304\n",
      "Step: 23 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.9355, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [24], Average Loss: 0.5241\n",
      "Step: 24 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.1289, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [25], Average Loss: 0.5209\n",
      "Step: 25 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.1738, device='cuda:0')\n",
      "Test accuracy of the model: 84.242 %\n",
      "Step [26], Average Loss: 0.5207\n",
      "Step: 26 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.2012, device='cuda:0')\n",
      "Test accuracy of the model: 83.942 %\n",
      "Step [27], Average Loss: 0.5220\n",
      "Step: 27 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.0195, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [28], Average Loss: 0.5214\n",
      "Step: 28 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.4824, device='cuda:0')\n",
      "Test accuracy of the model: 83.842 %\n",
      "Step [29], Average Loss: 0.5197\n",
      "Step: 29 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.0117, device='cuda:0')\n",
      "Test accuracy of the model: 83.862 %\n",
      "Step [30], Average Loss: 0.5210\n",
      "Step: 30 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.0137, device='cuda:0')\n",
      "Test accuracy of the model: 83.732 %\n",
      "Step [31], Average Loss: 0.5206\n",
      "Step: 31 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.0117, device='cuda:0')\n",
      "Test accuracy of the model: 84.002 %\n",
      "Step [32], Average Loss: 0.5209\n",
      "Step: 32 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.4121, device='cuda:0')\n",
      "Test accuracy of the model: 84.192 %\n",
      "Step [33], Average Loss: 0.5225\n",
      "Step: 33 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.1719, device='cuda:0')\n",
      "Test accuracy of the model: 84.412 %\n",
      "Step [34], Average Loss: 0.5216\n",
      "Step: 34 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.2598, device='cuda:0')\n",
      "Test accuracy of the model: 84.022 %\n",
      "Step [35], Average Loss: 0.5220\n",
      "Step: 35 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.4062, device='cuda:0')\n",
      "Test accuracy of the model: 84.052 %\n",
      "Step [36], Average Loss: 0.5221\n",
      "Step: 36 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.5039, device='cuda:0')\n",
      "Test accuracy of the model: 84.052 %\n",
      "Step [37], Average Loss: 0.5222\n",
      "Step: 37 Rejects: 7\n",
      "Hamiltonian diff: tensor(-0.3633, device='cuda:0')\n",
      "Test accuracy of the model: 84.052 %\n",
      "Step [38], Average Loss: 0.5226\n",
      "Step: 38 Rejects: 8\n",
      "Hamiltonian diff: tensor(-0.6445, device='cuda:0')\n",
      "Test accuracy of the model: 83.922 %\n",
      "Step [39], Average Loss: 0.5110\n",
      "Step: 39 Rejects: 8\n",
      "Hamiltonian diff: tensor(0.3672, device='cuda:0')\n",
      "Test accuracy of the model: 84.162 %\n",
      "Step [40], Average Loss: 0.5190\n",
      "Step: 40 Rejects: 8\n",
      "Hamiltonian diff: tensor(-0.0527, device='cuda:0')\n",
      "Test accuracy of the model: 84.142 %\n",
      "Step [41], Average Loss: 0.5189\n",
      "Step: 41 Rejects: 8\n",
      "Hamiltonian diff: tensor(0.2285, device='cuda:0')\n",
      "Test accuracy of the model: 83.912 %\n",
      "Step [42], Average Loss: 0.5175\n",
      "Step: 42 Rejects: 8\n",
      "Hamiltonian diff: tensor(-0.4961, device='cuda:0')\n",
      "Test accuracy of the model: 83.912 %\n",
      "Step [43], Average Loss: 0.5198\n",
      "Step: 43 Rejects: 9\n",
      "Hamiltonian diff: tensor(0.0996, device='cuda:0')\n",
      "Test accuracy of the model: 83.852 %\n",
      "Step [44], Average Loss: 0.5172\n",
      "Step: 44 Rejects: 9\n",
      "Hamiltonian diff: tensor(0.0996, device='cuda:0')\n",
      "Test accuracy of the model: 84.062 %\n",
      "Step [45], Average Loss: 0.5298\n",
      "Step: 45 Rejects: 9\n",
      "Hamiltonian diff: tensor(-0.1328, device='cuda:0')\n",
      "Test accuracy of the model: 84.062 %\n",
      "Step [46], Average Loss: 0.5284\n",
      "Step: 46 Rejects: 10\n",
      "Hamiltonian diff: tensor(-0.0977, device='cuda:0')\n",
      "Test accuracy of the model: 83.712 %\n",
      "Step [47], Average Loss: 0.5325\n",
      "Step: 47 Rejects: 10\n",
      "Hamiltonian diff: tensor(-1.6895, device='cuda:0')\n",
      "Test accuracy of the model: 83.712 %\n",
      "Step [48], Average Loss: 0.5454\n",
      "Step: 48 Rejects: 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-50fa9f598798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_labels_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_prob_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrejects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHMC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_leapfrog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-5de82153f1f3>\u001b[0m in \u001b[0;36mHMC\u001b[1;34m(num_steps, num_leapfrog, h, partial)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mham_old\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhamiltonian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_leapfrog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m       \u001b[0mleapfrog_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mham_new\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhamiltonian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2d1a33a02564>\u001b[0m in \u001b[0;36mleapfrog_step\u001b[1;34m(net, h)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mleapfrog_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2d1a33a02564>\u001b[0m in \u001b[0;36mfull_grad\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mfull_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimages_regulariser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain_data_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mfull_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3bd80b68fe19>\u001b[0m in \u001b[0;36mimages_regulariser\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnot_penalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'bias'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpenalized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mli_reg_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#for p in net.parameters():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#        li_reg_loss += (p**2).sum()*0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Daniel Paulin\\.conda\\envs\\torchenv39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h=torch.tensor(2e-3)\n",
    "num_steps=int(100)\n",
    "num_leapfrog=100\n",
    "\n",
    "\n",
    "test_labels_arr,test_prob_arr,rejects=HMC(num_steps,num_leapfrog,h,0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Rejects: 0\n",
      "Hamiltonian diff: tensor(-1.1172, device='cuda:0')\n",
      "Test accuracy of the model: 84.222 %\n",
      "Step [1], Average Loss: 0.4563\n",
      "Step: 1 Rejects: 0\n",
      "Hamiltonian diff: tensor(0.5664, device='cuda:0')\n",
      "Test accuracy of the model: 84.072 %\n",
      "Step [2], Average Loss: 0.4605\n",
      "Step: 2 Rejects: 0\n",
      "Hamiltonian diff: tensor(-0.2871, device='cuda:0')\n",
      "Test accuracy of the model: 84.072 %\n",
      "Step [3], Average Loss: 0.4690\n",
      "Step: 3 Rejects: 1\n",
      "Hamiltonian diff: tensor(0.2324, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [4], Average Loss: 0.4684\n",
      "Step: 4 Rejects: 1\n",
      "Hamiltonian diff: tensor(-1.1016, device='cuda:0')\n",
      "Test accuracy of the model: 84.172 %\n",
      "Step [5], Average Loss: 0.4727\n",
      "Step: 5 Rejects: 2\n",
      "Hamiltonian diff: tensor(0.2422, device='cuda:0')\n",
      "Test accuracy of the model: 84.192 %\n",
      "Step [6], Average Loss: 0.4738\n",
      "Step: 6 Rejects: 2\n",
      "Hamiltonian diff: tensor(-1.1816, device='cuda:0')\n",
      "Test accuracy of the model: 84.192 %\n",
      "Step [7], Average Loss: 0.4788\n",
      "Step: 7 Rejects: 3\n",
      "Hamiltonian diff: tensor(-0.0039, device='cuda:0')\n",
      "Test accuracy of the model: 84.062 %\n",
      "Step [8], Average Loss: 0.4784\n",
      "Step: 8 Rejects: 3\n",
      "Hamiltonian diff: tensor(-0.3789, device='cuda:0')\n",
      "Test accuracy of the model: 83.972 %\n",
      "Step [9], Average Loss: 0.4840\n",
      "Step: 9 Rejects: 3\n",
      "Hamiltonian diff: tensor(-0.5234, device='cuda:0')\n",
      "Test accuracy of the model: 83.972 %\n",
      "Step [10], Average Loss: 0.4858\n",
      "Step: 10 Rejects: 4\n",
      "Hamiltonian diff: tensor(-1.0840, device='cuda:0')\n",
      "Test accuracy of the model: 84.082 %\n",
      "Step [11], Average Loss: 0.4846\n",
      "Step: 11 Rejects: 4\n",
      "Hamiltonian diff: tensor(-0.6152, device='cuda:0')\n",
      "Test accuracy of the model: 84.002 %\n",
      "Step [12], Average Loss: 0.4919\n",
      "Step: 12 Rejects: 4\n",
      "Hamiltonian diff: tensor(0.4941, device='cuda:0')\n",
      "Test accuracy of the model: 83.912 %\n",
      "Step [13], Average Loss: 0.4940\n",
      "Step: 13 Rejects: 4\n",
      "Hamiltonian diff: tensor(1.1875, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [14], Average Loss: 0.4973\n",
      "Step: 14 Rejects: 4\n",
      "Hamiltonian diff: tensor(-3.8066, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [15], Average Loss: 0.5009\n",
      "Step: 15 Rejects: 5\n",
      "Hamiltonian diff: tensor(-1.5391, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [16], Average Loss: 0.4995\n",
      "Step: 16 Rejects: 6\n",
      "Hamiltonian diff: tensor(0.0996, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [17], Average Loss: 0.4998\n",
      "Step: 17 Rejects: 6\n",
      "Hamiltonian diff: tensor(-0.5195, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [18], Average Loss: 0.5042\n",
      "Step: 18 Rejects: 7\n",
      "Hamiltonian diff: tensor(-1.7578, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [19], Average Loss: 0.5058\n",
      "Step: 19 Rejects: 8\n",
      "Hamiltonian diff: tensor(-0.9961, device='cuda:0')\n",
      "Test accuracy of the model: 83.792 %\n",
      "Step [20], Average Loss: 0.5039\n",
      "Step: 20 Rejects: 8\n",
      "Hamiltonian diff: tensor(0.4434, device='cuda:0')\n",
      "Test accuracy of the model: 83.912 %\n",
      "Step [21], Average Loss: 0.5099\n",
      "Step: 21 Rejects: 8\n",
      "Hamiltonian diff: tensor(-1.6621, device='cuda:0')\n",
      "Test accuracy of the model: 83.912 %\n",
      "Step [22], Average Loss: 0.5118\n",
      "Step: 22 Rejects: 9\n",
      "Hamiltonian diff: tensor(-0.2188, device='cuda:0')\n",
      "Test accuracy of the model: 83.752 %\n",
      "Step [23], Average Loss: 0.5116\n",
      "Step: 23 Rejects: 9\n",
      "Hamiltonian diff: tensor(-1.1895, device='cuda:0')\n",
      "Test accuracy of the model: 83.752 %\n",
      "Step [24], Average Loss: 0.5146\n",
      "Step: 24 Rejects: 10\n",
      "Hamiltonian diff: tensor(-1.6797, device='cuda:0')\n",
      "Test accuracy of the model: 83.752 %\n",
      "Step [25], Average Loss: 0.5171\n",
      "Step: 25 Rejects: 10\n",
      "Hamiltonian diff: tensor(-0.1504, device='cuda:0')\n",
      "Test accuracy of the model: 84.072 %\n",
      "Step [26], Average Loss: 0.5229\n",
      "Step: 26 Rejects: 10\n",
      "Hamiltonian diff: tensor(-0.5234, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [27], Average Loss: 0.5229\n",
      "Step: 27 Rejects: 10\n",
      "Hamiltonian diff: tensor(-2.9395, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [28], Average Loss: 0.5234\n",
      "Step: 28 Rejects: 11\n",
      "Hamiltonian diff: tensor(-2.3887, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [29], Average Loss: 0.5234\n",
      "Step: 29 Rejects: 12\n",
      "Hamiltonian diff: tensor(-0.5020, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [30], Average Loss: 0.5177\n",
      "Step: 30 Rejects: 13\n",
      "Hamiltonian diff: tensor(-0.5195, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [31], Average Loss: 0.5199\n",
      "Step: 31 Rejects: 14\n",
      "Hamiltonian diff: tensor(-0.8730, device='cuda:0')\n",
      "Test accuracy of the model: 84.032 %\n",
      "Step [32], Average Loss: 0.5179\n",
      "Step: 32 Rejects: 15\n",
      "Hamiltonian diff: tensor(-0.7949, device='cuda:0')\n",
      "Test accuracy of the model: 84.092 %\n",
      "Step [33], Average Loss: 0.5189\n",
      "Step: 33 Rejects: 15\n",
      "Hamiltonian diff: tensor(-0.5430, device='cuda:0')\n",
      "Test accuracy of the model: 83.992 %\n",
      "Step [34], Average Loss: 0.5211\n",
      "Step: 34 Rejects: 15\n",
      "Hamiltonian diff: tensor(0.0723, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [35], Average Loss: 0.5222\n",
      "Step: 35 Rejects: 15\n",
      "Hamiltonian diff: tensor(0.5273, device='cuda:0')\n",
      "Test accuracy of the model: 84.042 %\n",
      "Step [36], Average Loss: 0.5231\n",
      "Step: 36 Rejects: 15\n",
      "Hamiltonian diff: tensor(-1.8750, device='cuda:0')\n",
      "Test accuracy of the model: 84.022 %\n",
      "Step [37], Average Loss: 0.5237\n",
      "Step: 37 Rejects: 15\n",
      "Hamiltonian diff: tensor(-1.0840, device='cuda:0')\n",
      "Test accuracy of the model: 84.022 %\n",
      "Step [38], Average Loss: 0.5227\n",
      "Step: 38 Rejects: 16\n",
      "Hamiltonian diff: tensor(-1.6699, device='cuda:0')\n",
      "Test accuracy of the model: 84.022 %\n",
      "Step [39], Average Loss: 0.5233\n",
      "Step: 39 Rejects: 17\n",
      "Hamiltonian diff: tensor(-0.0625, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [40], Average Loss: 0.5191\n",
      "Step: 40 Rejects: 17\n",
      "Hamiltonian diff: tensor(-3.7852, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [41], Average Loss: 0.5218\n",
      "Step: 41 Rejects: 18\n",
      "Hamiltonian diff: tensor(-1.7559, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [42], Average Loss: 0.5231\n",
      "Step: 42 Rejects: 19\n",
      "Hamiltonian diff: tensor(-2.0391, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [43], Average Loss: 0.5188\n",
      "Step: 43 Rejects: 20\n",
      "Hamiltonian diff: tensor(-2.1875, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [44], Average Loss: 0.5202\n",
      "Step: 44 Rejects: 21\n",
      "Hamiltonian diff: tensor(-13.0254, device='cuda:0')\n",
      "Test accuracy of the model: 83.812 %\n",
      "Step [45], Average Loss: 0.5184\n",
      "Step: 45 Rejects: 22\n",
      "Hamiltonian diff: tensor(-0.0918, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [46], Average Loss: 0.5169\n",
      "Step: 46 Rejects: 22\n",
      "Hamiltonian diff: tensor(-1.3242, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [47], Average Loss: 0.5230\n",
      "Step: 47 Rejects: 23\n",
      "Hamiltonian diff: tensor(-1.3164, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [48], Average Loss: 0.5262\n",
      "Step: 48 Rejects: 24\n",
      "Hamiltonian diff: tensor(-3.2383, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [49], Average Loss: 0.5251\n",
      "Step: 49 Rejects: 25\n",
      "Hamiltonian diff: tensor(-1.6895, device='cuda:0')\n",
      "Test accuracy of the model: 83.892 %\n",
      "Step [50], Average Loss: 0.5262\n",
      "Step: 50 Rejects: 26\n",
      "Hamiltonian diff: tensor(-1.8008, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [51], Average Loss: 0.5246\n",
      "Step: 51 Rejects: 26\n",
      "Hamiltonian diff: tensor(-5.9238, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [52], Average Loss: 0.5288\n",
      "Step: 52 Rejects: 27\n",
      "Hamiltonian diff: tensor(-2.0547, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [53], Average Loss: 0.5307\n",
      "Step: 53 Rejects: 28\n",
      "Hamiltonian diff: tensor(-1.3223, device='cuda:0')\n",
      "Test accuracy of the model: 83.822 %\n",
      "Step [54], Average Loss: 0.5266\n",
      "Step: 54 Rejects: 29\n",
      "Hamiltonian diff: tensor(0.1074, device='cuda:0')\n",
      "Test accuracy of the model: 83.742 %\n",
      "Step [55], Average Loss: 0.5295\n",
      "Step: 55 Rejects: 29\n",
      "Hamiltonian diff: tensor(-0.0664, device='cuda:0')\n",
      "Test accuracy of the model: 83.702 %\n",
      "Step [56], Average Loss: 0.5339\n",
      "Step: 56 Rejects: 29\n",
      "Hamiltonian diff: tensor(-0.7422, device='cuda:0')\n",
      "Test accuracy of the model: 83.702 %\n",
      "Step [57], Average Loss: 0.5343\n",
      "Step: 57 Rejects: 30\n",
      "Hamiltonian diff: tensor(-0.1426, device='cuda:0')\n",
      "Test accuracy of the model: 83.562 %\n",
      "Step [58], Average Loss: 0.5358\n",
      "Step: 58 Rejects: 30\n",
      "Hamiltonian diff: tensor(0.1270, device='cuda:0')\n",
      "Test accuracy of the model: 83.622 %\n",
      "Step [59], Average Loss: 0.5405\n",
      "Step: 59 Rejects: 30\n",
      "Hamiltonian diff: tensor(-0.8848, device='cuda:0')\n",
      "Test accuracy of the model: 83.622 %\n",
      "Step [60], Average Loss: 0.5417\n",
      "Step: 60 Rejects: 31\n",
      "Hamiltonian diff: tensor(0.0723, device='cuda:0')\n",
      "Test accuracy of the model: 83.622 %\n",
      "Step [61], Average Loss: 0.5445\n",
      "Step: 61 Rejects: 31\n",
      "Hamiltonian diff: tensor(-0.4688, device='cuda:0')\n",
      "Test accuracy of the model: 83.752 %\n",
      "Step [62], Average Loss: 0.5510\n",
      "Step: 62 Rejects: 31\n",
      "Hamiltonian diff: tensor(1.0586, device='cuda:0')\n",
      "Test accuracy of the model: 83.832 %\n",
      "Step [63], Average Loss: 0.5509\n",
      "Step: 63 Rejects: 31\n",
      "Hamiltonian diff: tensor(-4.3672, device='cuda:0')\n",
      "Test accuracy of the model: 83.832 %\n",
      "Step [64], Average Loss: 0.5484\n",
      "Step: 64 Rejects: 32\n",
      "Hamiltonian diff: tensor(-0.8125, device='cuda:0')\n",
      "Test accuracy of the model: 83.832 %\n",
      "Step [65], Average Loss: 0.5495\n",
      "Step: 65 Rejects: 33\n",
      "Hamiltonian diff: tensor(0.7969, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [66], Average Loss: 0.5409\n",
      "Step: 66 Rejects: 33\n",
      "Hamiltonian diff: tensor(-6.1172, device='cuda:0')\n",
      "Test accuracy of the model: 83.952 %\n",
      "Step [67], Average Loss: 0.5421\n",
      "Step: 67 Rejects: 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6902279e1b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_symmetric_sweeps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest_labels_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_prob_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrejects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSMS_HMC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_symmetric_sweeps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-5de82153f1f3>\u001b[0m in \u001b[0;36mSMS_HMC\u001b[1;34m(num_steps, num_symmetric_sweeps, h, partial)\u001b[0m\n\u001b[0;32m     24\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_batches\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mind_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mleapfrogvxv_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mham_new\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhamiltonian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2d1a33a02564>\u001b[0m in \u001b[0;36mleapfrogvxv_step\u001b[1;34m(net, h, batch_it)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0msvrg_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvrg_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2d1a33a02564>\u001b[0m in \u001b[0;36msvrg_grad\u001b[1;34m(net, batch_it)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mloss_likelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mgrads_likelihood\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Daniel Paulin\\.conda\\envs\\torchenv39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             )\n\u001b[1;32m--> 525\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\Daniel Paulin\\.conda\\envs\\torchenv39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     _engine_run_backward(\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Daniel Paulin\\.conda\\envs\\torchenv39\\lib\\site-packages\\torch\\autograd\\graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h=torch.tensor(6e-5)\n",
    "num_steps=int(100)\n",
    "num_symmetric_sweeps=10\n",
    "\n",
    "test_labels_arr,test_prob_arr,rejects=SMS_HMC(num_steps,num_symmetric_sweeps,h,0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.333333333333336"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e-3/6e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob=torch.Tensor(test_prob_arr[:,:,(1*num_steps//5):num_steps]).mean(-1).reshape(test_size,num_classes)\n",
    "rps_arr=(rps_calc(test_prob, test_labels_arr).mean())\n",
    "nll_arr=nll_calc(test_prob, test_labels_arr)\n",
    "ace_arr=adaptive_calibration_error(test_prob, test_labels_arr).mean()\n",
    "_, predictedt = torch.max(test_prob,1)\n",
    "acc_arr=(predictedt==test_labels_arr.reshape(1,test_size)).sum()/test_size\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pytorch MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
